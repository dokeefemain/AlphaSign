{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwvnXbYWXIea",
    "outputId": "dd674b7e-730b-4c09-ef30-329a42572b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr  2 22:17:46 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQzntgF6wcgj",
    "outputId": "7c2cfd46-776c-4e8d-99c7-74d19830afc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4xtAuPPJw6_H",
    "outputId": "984ce95d-8080-48f5-e161-047a3f3c2b0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  drive/My Drive/datasets/train1.zip/train1.zip\n",
      "   creating: train1/\n",
      "  inflating: train1/X_train1.npy     \n",
      "  inflating: train1/X_val1.npy       \n",
      "  inflating: train1/y_train_e1.npy   \n",
      "  inflating: train1/y_val_e1.npy     \n"
     ]
    }
   ],
   "source": [
    "!unzip drive/My\\ Drive/datasets/train1.zip/train1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cIgRBrbSxyy7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "y5hmGnl-x38I"
   },
   "outputs": [],
   "source": [
    "X_train = np.load(\"lib/datasets/train1/X_train1.npy\")\n",
    "X_val = np.load(\"lib/datasets/train1/X_val1.npy\")\n",
    "y_train_e = np.load(\"lib/datasets/train1/y_train_e1.npy\")\n",
    "y_val_e = np.load(\"lib/datasets/train1/y_val_e1.npy\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Q0ieT8cxyGH1"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, MaxPool2D, UpSampling2D, AveragePooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Add, Multiply, BatchNormalization, Dropout, concatenate\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "class IRV2():\n",
    "    def __init__(self, input_shape, n_classes, activation, p=1, t=2, r=1, scale1=0.17, scale2=0.1, scale3=0.2):\n",
    "        self.input_shape = input_shape\n",
    "        self.n_classes = n_classes\n",
    "        self.activation = activation\n",
    "        self.scale1 = scale1\n",
    "        self.scale2 = scale2\n",
    "        self.scale3 = scale3\n",
    "\n",
    "    def build_model(self):\n",
    "        input_data = Input(shape=self.input_shape)\n",
    "        stem = self.stem(input_data)\n",
    "        ira = Activation(\"relu\")(stem)\n",
    "        for i in range(5):\n",
    "            ira = self.IRA(ira)\n",
    "\n",
    "        ra = self.RA(ira)\n",
    "\n",
    "        irb = Activation(\"relu\")(ra)\n",
    "        for i in range(10):\n",
    "            irb = self.IRB(irb)\n",
    "\n",
    "        rb = self.RB(irb)\n",
    "\n",
    "        irc = Activation(\"relu\")(rb)\n",
    "        for i in range(5):\n",
    "            irc = self.IRC(irc)\n",
    "\n",
    "        pool = GlobalAveragePooling2D()(irc)\n",
    "\n",
    "        drop = Dropout(0.2)(pool)\n",
    "        final = Dense(self.n_classes, activation= self.activation)(drop)\n",
    "        model = Model(inputs = input_data, outputs = final)\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def stem(self, input_data):\n",
    "        conv_1 = Conv2D(32, (3,3), strides=2, padding=\"valid\")(input_data)\n",
    "        conv_1 = BatchNormalization()(conv_1)\n",
    "        conv_1 = Activation('relu')(conv_1)\n",
    "\n",
    "        conv_2 = Conv2D(32, (3, 3), padding=\"valid\")(conv_1)\n",
    "        conv_2 = BatchNormalization()(conv_2)\n",
    "        conv_2 = Activation('relu')(conv_2)\n",
    "\n",
    "        conv_3 = Conv2D(64, (3, 3), padding=\"same\")(conv_2)\n",
    "        conv_3 = BatchNormalization()(conv_3)\n",
    "        conv_3 = Activation('relu')(conv_3)\n",
    "\n",
    "        pool_1 = MaxPool2D((3,3), strides=2, padding='valid')(conv_3)\n",
    "\n",
    "        conv_4 = Conv2D(96, (3, 3), strides = 2, padding=\"valid\")(conv_3)\n",
    "        conv_4 = BatchNormalization()(conv_4)\n",
    "        conv_4 = Activation('relu')(conv_4)\n",
    "\n",
    "        conc_1 = concatenate([pool_1, conv_4])\n",
    "\n",
    "        conv_5_1 = Conv2D(64, (1, 1), padding=\"same\")(conc_1)\n",
    "        conv_5_1 = BatchNormalization()(conv_5_1)\n",
    "        conv_5_1 = Activation('relu')(conv_5_1)\n",
    "\n",
    "        conv_6_1 = Conv2D(96, (3, 3), padding=\"valid\")(conv_5_1)\n",
    "        conv_6_1 = BatchNormalization()(conv_6_1)\n",
    "        conv_6_1 = Activation('relu')(conv_6_1)\n",
    "\n",
    "        conv_5_2 = Conv2D(64, (1, 1), padding=\"same\")(conc_1)\n",
    "        conv_5_2 = BatchNormalization()(conv_5_2)\n",
    "        conv_5_2 = Activation('relu')(conv_5_2)\n",
    "\n",
    "        conv_6_2 = Conv2D(64, (7, 1), padding=\"same\")(conv_5_2)\n",
    "        conv_6_2 = BatchNormalization()(conv_6_2)\n",
    "        conv_6_2 = Activation('relu')(conv_6_2)\n",
    "\n",
    "        conv_7_2 = Conv2D(64, (1, 7), padding=\"same\")(conv_6_2)\n",
    "        conv_7_2 = BatchNormalization()(conv_7_2)\n",
    "        conv_7_2 = Activation('relu')(conv_7_2)\n",
    "\n",
    "        conv_8_2 = Conv2D(96, (3, 3), padding=\"valid\")(conv_7_2)\n",
    "        conv_8_2 = BatchNormalization()(conv_8_2)\n",
    "        conv_8_2 = Activation('relu')(conv_8_2)\n",
    "\n",
    "        conc_2 = concatenate([conv_6_1, conv_8_2])\n",
    "\n",
    "        conv_1_3 = Conv2D(192, (3,3),strides=2, padding=\"valid\")(conc_2)\n",
    "        conv_1_3 = BatchNormalization()(conv_1_3)\n",
    "        conv_1_3 = Activation(\"relu\")(conv_1_3)\n",
    "\n",
    "        pool_1_4 = MaxPool2D(strides=2, padding = \"valid\")(conc_2)\n",
    "\n",
    "        conc_3 = concatenate([conv_1_3, pool_1_4])\n",
    "\n",
    "        return conc_3\n",
    "\n",
    "    #fig 16\n",
    "    def IRA(self, input_data):\n",
    "        # relu_1 = Activation(\"relu\")(input_data)\n",
    "        b_0 = Conv2D(32, (1,1), padding=\"same\")(input_data)\n",
    "        b_0 = BatchNormalization()(b_0)\n",
    "        b_0 = Activation(\"relu\")(b_0)\n",
    "\n",
    "        b_1 = Conv2D(32, (1, 1), padding=\"same\")(input_data)\n",
    "        b_1 = BatchNormalization()(b_1)\n",
    "        b_1 = Activation(\"relu\")(b_1)\n",
    "        b_1 = Conv2D(32, (3, 3), padding=\"same\")(b_1)\n",
    "        b_1 = BatchNormalization()(b_1)\n",
    "        b_1 = Activation(\"relu\")(b_1)\n",
    "\n",
    "        b_2 = Conv2D(32, (1, 1), padding=\"same\")(input_data)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(48, (3, 3), padding=\"same\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(64, (3, 3), padding=\"same\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "\n",
    "        conc_1 = concatenate([b_0, b_1, b_2])\n",
    "\n",
    "        conv = Conv2D(384, (1,1), padding=\"same\")(conc_1)\n",
    "\n",
    "        out = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
    "               output_shape=K.int_shape(conv)[1:],\n",
    "               arguments={'scale': self.scale1})([input_data, conv])\n",
    "        out = Activation(\"relu\")(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    # fig 7\n",
    "    # k l m n = 256 256 384 384\n",
    "    def RA(self, input_data):\n",
    "        b_0 = MaxPool2D((3,3), strides=2, padding=\"valid\")(input_data)\n",
    "\n",
    "        b_1 = Conv2D(384, (3,3), strides=2, padding=\"valid\")(input_data)\n",
    "        b_1 = BatchNormalization()(b_1)\n",
    "        b_1 = Activation(\"relu\")(b_1)\n",
    "\n",
    "        b_2 = Conv2D(256, (1,1), padding=\"same\")(input_data)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(256, (3,3), padding=\"same\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(384, (3,3), strides=2, padding=\"valid\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "\n",
    "        conc_1 = concatenate([b_0, b_1, b_2])\n",
    "\n",
    "        return conc_1\n",
    "\n",
    "    # fig 17\n",
    "    def IRB(self, input_data):\n",
    "        b_1 = Conv2D(192, (1,1), padding=\"same\")(input_data)\n",
    "        b_1 = BatchNormalization()(b_1)\n",
    "        b_1 = Activation(\"relu\")(b_1)\n",
    "\n",
    "        b_2 = Conv2D(128, (1,1), padding=\"same\")(input_data)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(160, (1,7), padding=\"same\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(192, (7,1), padding=\"same\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "\n",
    "        conc_1 = concatenate([b_1, b_2])\n",
    "\n",
    "        conv = Conv2D(1152, (1,1), padding=\"same\")(conc_1)\n",
    "\n",
    "        out = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
    "               output_shape=K.int_shape(conv)[1:],\n",
    "               arguments={'scale': self.scale2})([input_data, conv])\n",
    "        out = Activation(\"relu\")(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def RB(self, input_data):\n",
    "        b_0 = MaxPool2D((3,3), strides=2, padding=\"valid\")(input_data)\n",
    "\n",
    "        b_1 = Conv2D(256, (1,1), padding=\"same\")(input_data)\n",
    "        b_1 = BatchNormalization()(b_1)\n",
    "        b_1 = Activation(\"relu\")(b_1)\n",
    "        b_1 = Conv2D(384, (3,3),strides=2, padding=\"valid\")(b_1)\n",
    "        b_1 = BatchNormalization()(b_1)\n",
    "        b_1 = Activation(\"relu\")(b_1)\n",
    "\n",
    "        b_2 = Conv2D(256, (1,1), padding=\"same\")(input_data)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(288, (3,3),strides=2, padding=\"valid\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "\n",
    "        b_3 = Conv2D(256, (1,1), padding=\"same\")(input_data)\n",
    "        b_3 = BatchNormalization()(b_3)\n",
    "        b_3 = Activation(\"relu\")(b_3)\n",
    "        b_3 = Conv2D(288, (3,3), padding=\"same\")(b_3)\n",
    "        b_3 = BatchNormalization()(b_3)\n",
    "        b_3 = Activation(\"relu\")(b_3)\n",
    "        b_3 = Conv2D(320, (3,3),strides=2, padding=\"valid\")(b_3)\n",
    "        b_3 = BatchNormalization()(b_3)\n",
    "        b_3 = Activation(\"relu\")(b_3)\n",
    "\n",
    "        conc = concatenate([b_0,b_1,b_2,b_3])\n",
    "        return conc\n",
    "\n",
    "    def IRC(self, input_data):\n",
    "        b_1 = Conv2D(192, (1,1), padding=\"same\")(input_data)\n",
    "        b_1 = BatchNormalization()(b_1)\n",
    "        b_1 = Activation(\"relu\")(b_1)\n",
    "\n",
    "        b_2 = Conv2D(192, (1,1), padding=\"same\")(input_data)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(224, (1,3), padding=\"same\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(256, (3,1), padding=\"same\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "\n",
    "        conc_1 = concatenate([b_1, b_2])\n",
    "\n",
    "        conv = Conv2D(2144, (1,1), padding=\"same\")(conc_1)\n",
    "        out = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
    "               output_shape=K.int_shape(conv)[1:],\n",
    "               arguments={'scale': self.scale3})([input_data, conv])\n",
    "        relu = Activation(\"relu\")(out)\n",
    "        return relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XkUK5BfiAqPL",
    "outputId": "d681accc-2d83-4602-fb78-05eb726f0d15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "  2/138 [..............................] - ETA: 1:09 - loss: 8.0697 - accuracy: 0.0469 "
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/conv2d_131/Conv2D' defined at (most recent call last):\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2915, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\dokee\\AppData\\Local\\Temp/ipykernel_11488/505143647.py\", line 14, in <module>\n      history = model.fit(X_train, y_train_e, batch_size=32, epochs=epochs, validation_data=(X_val, y_val_e))\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 240, in convolution_op\n      name=self.__class__.__name__)\nNode: 'model/conv2d_131/Conv2D'\nOOM when allocating tensor with shape[2144,448,1,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv2d_131/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_28882]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11488/505143647.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 metrics=['accuracy'])\n\u001b[0;32m     13\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_e\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val_e\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/conv2d_131/Conv2D' defined at (most recent call last):\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2915, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\dokee\\AppData\\Local\\Temp/ipykernel_11488/505143647.py\", line 14, in <module>\n      history = model.fit(X_train, y_train_e, batch_size=32, epochs=epochs, validation_data=(X_val, y_val_e))\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 240, in convolution_op\n      name=self.__class__.__name__)\nNode: 'model/conv2d_131/Conv2D'\nOOM when allocating tensor with shape[2144,448,1,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv2d_131/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_28882]"
     ]
    }
   ],
   "source": [
    "#11:30\n",
    "import gc\n",
    "test_scales = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "test = []\n",
    "model = []\n",
    "i, j, k = 0.2, 0.3, 0.25\n",
    "\n",
    "# tf.keras.backend.clear_session()\n",
    "# tf.keras.backend.set_learning_phase(True)\n",
    "model = IRV2(X_train.shape[1:], 48, activation= 'softmax', scale1=i, scale2=j, scale3=k).build_model()\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=\"adam\",\n",
    "                metrics=['accuracy'])\n",
    "epochs = 40\n",
    "history = model.fit(X_train, y_train_e, batch_size=32, epochs=epochs, validation_data=(X_val, y_val_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-Yz4tA8QQiZ",
    "outputId": "06826601-7b3b-4fc5-c5c9-01d53175bae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1880\n"
     ]
    }
   ],
   "source": [
    "reset_keras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NxbC_HoC8zS",
    "outputId": "616262ac-9bbe-4d4e-b105-5ffd8d30e108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.1 0.2\n",
      "0.1 0.1 0.25\n",
      "0.1 0.1 0.3\n",
      "0.1 0.15 0.1\n",
      "0.1 0.15 0.15\n",
      "0.1 0.15 0.2\n",
      "0.1 0.15 0.25\n",
      "0.1 0.15 0.3\n",
      "0.1 0.2 0.1\n",
      "0.1 0.2 0.15\n",
      "0.1 0.2 0.2\n",
      "0.1 0.2 0.25\n",
      "0.1 0.2 0.3\n",
      "0.1 0.25 0.1\n",
      "0.1 0.25 0.15\n",
      "0.1 0.25 0.2\n",
      "0.1 0.25 0.25\n",
      "0.1 0.25 0.3\n",
      "0.1 0.3 0.1\n",
      "0.1 0.3 0.15\n",
      "0.1 0.3 0.2\n",
      "0.1 0.3 0.25\n",
      "0.1 0.3 0.3\n",
      "0.15 0.1 0.1\n",
      "0.15 0.1 0.15\n",
      "0.15 0.1 0.2\n",
      "0.15 0.1 0.25\n",
      "0.15 0.1 0.3\n",
      "0.15 0.15 0.1\n",
      "0.15 0.15 0.15\n",
      "0.15 0.15 0.2\n",
      "0.15 0.15 0.25\n",
      "0.15 0.15 0.3\n",
      "0.15 0.2 0.1\n",
      "0.15 0.2 0.15\n",
      "0.15 0.2 0.2\n",
      "0.15 0.2 0.25\n",
      "0.15 0.2 0.3\n",
      "0.15 0.25 0.1\n",
      "0.15 0.25 0.15\n",
      "0.15 0.25 0.2\n",
      "0.15 0.25 0.25\n",
      "0.15 0.25 0.3\n",
      "0.15 0.3 0.1\n",
      "0.15 0.3 0.15\n",
      "0.15 0.3 0.2\n",
      "0.15 0.3 0.25\n",
      "0.15 0.3 0.3\n",
      "0.2 0.1 0.1\n",
      "0.2 0.1 0.15\n",
      "0.2 0.1 0.2\n",
      "0.2 0.1 0.25\n",
      "0.2 0.1 0.3\n",
      "0.2 0.15 0.1\n",
      "0.2 0.15 0.15\n",
      "0.2 0.15 0.2\n",
      "0.2 0.15 0.25\n",
      "0.2 0.15 0.3\n",
      "0.2 0.2 0.1\n",
      "0.2 0.2 0.15\n",
      "0.2 0.2 0.2\n",
      "0.2 0.2 0.25\n",
      "0.2 0.2 0.3\n",
      "0.2 0.25 0.1\n",
      "0.2 0.25 0.15\n",
      "0.2 0.25 0.2\n",
      "0.2 0.25 0.25\n",
      "0.2 0.25 0.3\n",
      "0.2 0.3 0.1\n",
      "0.2 0.3 0.15\n",
      "0.2 0.3 0.2\n",
      "0.2 0.3 0.25\n",
      "0.2 0.3 0.3\n",
      "0.25 0.1 0.1\n",
      "0.25 0.1 0.15\n",
      "0.25 0.1 0.2\n",
      "0.25 0.1 0.25\n",
      "0.25 0.1 0.3\n",
      "0.25 0.15 0.1\n",
      "0.25 0.15 0.15\n",
      "0.25 0.15 0.2\n",
      "0.25 0.15 0.25\n",
      "0.25 0.15 0.3\n",
      "0.25 0.2 0.1\n",
      "0.25 0.2 0.15\n",
      "0.25 0.2 0.2\n",
      "0.25 0.2 0.25\n",
      "0.25 0.2 0.3\n",
      "0.25 0.25 0.1\n",
      "0.25 0.25 0.15\n",
      "0.25 0.25 0.2\n",
      "0.25 0.25 0.25\n",
      "0.25 0.25 0.3\n",
      "0.25 0.3 0.1\n",
      "0.25 0.3 0.15\n",
      "0.25 0.3 0.2\n",
      "0.25 0.3 0.25\n",
      "0.25 0.3 0.3\n",
      "0.3 0.1 0.1\n",
      "0.3 0.1 0.15\n",
      "0.3 0.1 0.2\n",
      "0.3 0.1 0.25\n",
      "0.3 0.1 0.3\n",
      "0.3 0.15 0.1\n",
      "0.3 0.15 0.15\n",
      "0.3 0.15 0.2\n",
      "0.3 0.15 0.25\n",
      "0.3 0.15 0.3\n",
      "0.3 0.2 0.1\n",
      "0.3 0.2 0.15\n",
      "0.3 0.2 0.2\n",
      "0.3 0.2 0.25\n",
      "0.3 0.2 0.3\n",
      "0.3 0.25 0.1\n",
      "0.3 0.25 0.15\n",
      "0.3 0.25 0.2\n",
      "0.3 0.25 0.25\n",
      "0.3 0.25 0.3\n",
      "0.3 0.3 0.1\n",
      "0.3 0.3 0.15\n",
      "0.3 0.3 0.2\n",
      "0.3 0.3 0.25\n",
      "0.3 0.3 0.3\n"
     ]
    }
   ],
   "source": [
    "test_scales = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "test = []\n",
    "for i in test_scales:\n",
    "    for j in test_scales:\n",
    "        for k in test_scales:\n",
    "            if i != 0.1 or j != 0.1 or (k != 0.1 and k != 0.15):\n",
    "                print(str(i) + ' ' + str(j) + ' ' + str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-2m1XDdnYXL-",
    "outputId": "d6037985-8d8f-40be-8054-837b0c10d51f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "138/138 [==============================] - 101s 516ms/step - loss: 2.7708 - accuracy: 0.3179 - val_loss: 87.5530 - val_accuracy: 0.1353\n",
      "Epoch 2/40\n",
      "138/138 [==============================] - 64s 462ms/step - loss: 2.1505 - accuracy: 0.3938 - val_loss: 2.0749 - val_accuracy: 0.4099\n",
      "Epoch 3/40\n",
      "138/138 [==============================] - 64s 462ms/step - loss: 1.8565 - accuracy: 0.4675 - val_loss: 1.8978 - val_accuracy: 0.4793\n",
      "Epoch 4/40\n",
      "138/138 [==============================] - 64s 461ms/step - loss: 1.5847 - accuracy: 0.5312 - val_loss: 2.5118 - val_accuracy: 0.4024\n",
      "Epoch 5/40\n",
      "138/138 [==============================] - 64s 461ms/step - loss: 1.2351 - accuracy: 0.6320 - val_loss: 1.2971 - val_accuracy: 0.6071\n",
      "Epoch 6/40\n",
      "138/138 [==============================] - 64s 461ms/step - loss: 0.9691 - accuracy: 0.7050 - val_loss: 1.4337 - val_accuracy: 0.6003\n",
      "Epoch 7/40\n",
      "138/138 [==============================] - 64s 461ms/step - loss: 0.7225 - accuracy: 0.7779 - val_loss: 1.6697 - val_accuracy: 0.5316\n",
      "Epoch 8/40\n",
      "138/138 [==============================] - 64s 460ms/step - loss: 0.5814 - accuracy: 0.8108 - val_loss: 1.2949 - val_accuracy: 0.6642\n",
      "Epoch 9/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.4426 - accuracy: 0.8602 - val_loss: 0.5833 - val_accuracy: 0.8368\n",
      "Epoch 10/40\n",
      "138/138 [==============================] - 64s 461ms/step - loss: 0.3718 - accuracy: 0.8804 - val_loss: 0.7010 - val_accuracy: 0.8015\n",
      "Epoch 11/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.3004 - accuracy: 0.9026 - val_loss: 1.0771 - val_accuracy: 0.6961\n",
      "Epoch 12/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.2918 - accuracy: 0.9046 - val_loss: 0.6567 - val_accuracy: 0.8137\n",
      "Epoch 13/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.2471 - accuracy: 0.9182 - val_loss: 0.5130 - val_accuracy: 0.8498\n",
      "Epoch 14/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.2170 - accuracy: 0.9232 - val_loss: 0.4435 - val_accuracy: 0.8776\n",
      "Epoch 15/40\n",
      "138/138 [==============================] - 64s 461ms/step - loss: 0.2018 - accuracy: 0.9279 - val_loss: 0.6935 - val_accuracy: 0.8035\n",
      "Epoch 16/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1999 - accuracy: 0.9311 - val_loss: 0.7650 - val_accuracy: 0.7831\n",
      "Epoch 17/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1951 - accuracy: 0.9295 - val_loss: 0.7603 - val_accuracy: 0.7920\n",
      "Epoch 18/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1813 - accuracy: 0.9309 - val_loss: 0.6521 - val_accuracy: 0.8253\n",
      "Epoch 19/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1722 - accuracy: 0.9341 - val_loss: 0.6267 - val_accuracy: 0.8266\n",
      "Epoch 20/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1625 - accuracy: 0.9395 - val_loss: 0.6772 - val_accuracy: 0.8226\n",
      "Epoch 21/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1551 - accuracy: 0.9395 - val_loss: 0.4961 - val_accuracy: 0.8606\n",
      "Epoch 22/40\n",
      "138/138 [==============================] - 64s 461ms/step - loss: 0.1592 - accuracy: 0.9343 - val_loss: 0.9281 - val_accuracy: 0.7492\n",
      "Epoch 23/40\n",
      "138/138 [==============================] - 64s 461ms/step - loss: 0.1504 - accuracy: 0.9372 - val_loss: 0.7180 - val_accuracy: 0.8131\n",
      "Epoch 24/40\n",
      "138/138 [==============================] - 64s 461ms/step - loss: 0.1639 - accuracy: 0.9370 - val_loss: 0.6439 - val_accuracy: 0.8144\n",
      "Epoch 25/40\n",
      "138/138 [==============================] - 64s 460ms/step - loss: 0.1464 - accuracy: 0.9436 - val_loss: 0.5372 - val_accuracy: 0.8545\n",
      "Epoch 26/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1348 - accuracy: 0.9436 - val_loss: 0.5934 - val_accuracy: 0.8423\n",
      "Epoch 27/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1319 - accuracy: 0.9479 - val_loss: 0.6529 - val_accuracy: 0.8402\n",
      "Epoch 28/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1289 - accuracy: 0.9438 - val_loss: 0.4900 - val_accuracy: 0.8634\n",
      "Epoch 29/40\n",
      "138/138 [==============================] - 64s 461ms/step - loss: 0.1202 - accuracy: 0.9497 - val_loss: 0.6597 - val_accuracy: 0.8192\n",
      "Epoch 30/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1345 - accuracy: 0.9458 - val_loss: 0.6003 - val_accuracy: 0.8375\n",
      "Epoch 31/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1459 - accuracy: 0.9411 - val_loss: 0.6611 - val_accuracy: 0.8266\n",
      "Epoch 32/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1620 - accuracy: 0.9366 - val_loss: 1.7139 - val_accuracy: 0.6635\n",
      "Epoch 33/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1419 - accuracy: 0.9413 - val_loss: 0.4910 - val_accuracy: 0.8749\n",
      "Epoch 34/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1129 - accuracy: 0.9483 - val_loss: 0.5482 - val_accuracy: 0.8586\n",
      "Epoch 35/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1170 - accuracy: 0.9440 - val_loss: 0.6357 - val_accuracy: 0.8396\n",
      "Epoch 36/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1091 - accuracy: 0.9495 - val_loss: 0.5447 - val_accuracy: 0.8688\n",
      "Epoch 37/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1163 - accuracy: 0.9477 - val_loss: 0.5828 - val_accuracy: 0.8681\n",
      "Epoch 38/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1027 - accuracy: 0.9529 - val_loss: 0.6284 - val_accuracy: 0.8586\n",
      "Epoch 39/40\n",
      "138/138 [==============================] - 63s 460ms/step - loss: 0.1068 - accuracy: 0.9515 - val_loss: 0.5130 - val_accuracy: 0.8586\n",
      "Epoch 40/40\n",
      "138/138 [==============================] - 64s 461ms/step - loss: 0.1024 - accuracy: 0.9520 - val_loss: 0.5566 - val_accuracy: 0.8634\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model = IRV2(X_train.shape[1:], 48, activation= 'softmax').build_model()\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "epochs = 40\n",
    "history = model.fit(X_train, y_train_e, batch_size=32, epochs=epochs, validation_data=(X_val, y_val_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZDxqLSnRCGE9",
    "outputId": "b9d67fe0-2f7b-4dd9-be12-265bfeefe3f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8776342868804932\n"
     ]
    }
   ],
   "source": [
    "print(max(history.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ht45Wk-YE6lR",
    "outputId": "7cf707b0-8bc2-4b87-e3c7-5e25032343a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: IRv2/assets\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_ff689642-2f41-4066-aa7a-77d0e1271db1\", \"history_IRv2_70.json\", 2877)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "import pandas as pd\n",
    "model.save(\"IRv2\")\n",
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "# save to json:  \n",
    "hist_json_file = 'history_IRv2_70.json' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_json(f)\n",
    "\n",
    "files.download('history_IRv2_70.json')\n",
    "#files.download('IRv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNCl9mB8z0yY"
   },
   "outputs": [],
   "source": [
    "model = IRV2(X_train.shape[1:], 47, activation= 'softmax').build_model()\n",
    "# decay = .9 e = 1.0 lr = 0.045, exp rate = 0.94\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.optimizers.SGD(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mJeMrTO5z7mB",
    "outputId": "cda7d6cf-c9d6-4c7b-d2bc-d90799120f25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "138/138 [==============================] - 31s 125ms/step - loss: 2.9496 - accuracy: 0.2343 - val_loss: 2.6825 - val_accuracy: 0.2726 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 2.6389 - accuracy: 0.2853 - val_loss: 2.4061 - val_accuracy: 0.3623 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 2.4183 - accuracy: 0.3435 - val_loss: 2.1711 - val_accuracy: 0.4310 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 2.1904 - accuracy: 0.3923 - val_loss: 1.9650 - val_accuracy: 0.4602 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "138/138 [==============================] - 13s 96ms/step - loss: 1.9691 - accuracy: 0.4521 - val_loss: 1.7649 - val_accuracy: 0.5337 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 1.7344 - accuracy: 0.5037 - val_loss: 1.5537 - val_accuracy: 0.5812 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 1.5851 - accuracy: 0.5531 - val_loss: 1.4082 - val_accuracy: 0.6288 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 1.3889 - accuracy: 0.5917 - val_loss: 1.2221 - val_accuracy: 0.6744 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 1.2411 - accuracy: 0.6447 - val_loss: 1.1187 - val_accuracy: 0.6785 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 1.0677 - accuracy: 0.6964 - val_loss: 0.9932 - val_accuracy: 0.7315 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "138/138 [==============================] - 13s 94ms/step - loss: 0.9639 - accuracy: 0.7242 - val_loss: 0.8906 - val_accuracy: 0.7600 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.8419 - accuracy: 0.7589 - val_loss: 0.8258 - val_accuracy: 0.7641 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.7771 - accuracy: 0.7791 - val_loss: 0.7726 - val_accuracy: 0.7906 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.6708 - accuracy: 0.8010 - val_loss: 0.7164 - val_accuracy: 0.7859 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.6089 - accuracy: 0.8180 - val_loss: 0.7143 - val_accuracy: 0.7981 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.5442 - accuracy: 0.8375 - val_loss: 0.6259 - val_accuracy: 0.8192 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.5070 - accuracy: 0.8545 - val_loss: 0.6367 - val_accuracy: 0.8205 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.4650 - accuracy: 0.8600 - val_loss: 0.5924 - val_accuracy: 0.8239 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.4350 - accuracy: 0.8715 - val_loss: 0.5771 - val_accuracy: 0.8219 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.3950 - accuracy: 0.8815 - val_loss: 0.5391 - val_accuracy: 0.8389 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.3814 - accuracy: 0.8856 - val_loss: 0.5382 - val_accuracy: 0.8423 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.3432 - accuracy: 0.8953 - val_loss: 0.5462 - val_accuracy: 0.8266 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.3381 - accuracy: 0.8980 - val_loss: 0.5354 - val_accuracy: 0.8382 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.3314 - accuracy: 0.8983 - val_loss: 0.5244 - val_accuracy: 0.8382 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.3005 - accuracy: 0.9044 - val_loss: 0.5022 - val_accuracy: 0.8525 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.3087 - accuracy: 0.8996 - val_loss: 0.4803 - val_accuracy: 0.8504 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.2792 - accuracy: 0.9119 - val_loss: 0.4937 - val_accuracy: 0.8457 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.2799 - accuracy: 0.9125 - val_loss: 0.4831 - val_accuracy: 0.8511 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.2559 - accuracy: 0.9153 - val_loss: 0.4843 - val_accuracy: 0.8532 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.2590 - accuracy: 0.9196 - val_loss: 0.4693 - val_accuracy: 0.8538 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.2533 - accuracy: 0.9198 - val_loss: 0.5021 - val_accuracy: 0.8498 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.2493 - accuracy: 0.9148 - val_loss: 0.4830 - val_accuracy: 0.8627 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.2354 - accuracy: 0.9223 - val_loss: 0.5057 - val_accuracy: 0.8430 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.2373 - accuracy: 0.9218 - val_loss: 0.4934 - val_accuracy: 0.8450 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "138/138 [==============================] - 13s 94ms/step - loss: 0.2244 - accuracy: 0.9252 - val_loss: 0.4727 - val_accuracy: 0.8620 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.2245 - accuracy: 0.9234 - val_loss: 0.5037 - val_accuracy: 0.8504 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.2264 - accuracy: 0.9214\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.2264 - accuracy: 0.9214 - val_loss: 0.4838 - val_accuracy: 0.8538 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.2033 - accuracy: 0.9311 - val_loss: 0.4746 - val_accuracy: 0.8579 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.1878 - accuracy: 0.9370 - val_loss: 0.4723 - val_accuracy: 0.8566 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.1925 - accuracy: 0.9293 - val_loss: 0.4723 - val_accuracy: 0.8600 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.1827 - accuracy: 0.9350 - val_loss: 0.4733 - val_accuracy: 0.8593 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.1871 - accuracy: 0.9336 - val_loss: 0.4727 - val_accuracy: 0.8552 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.9370\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.1741 - accuracy: 0.9370 - val_loss: 0.4769 - val_accuracy: 0.8559 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.1674 - accuracy: 0.9409 - val_loss: 0.4765 - val_accuracy: 0.8552 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.1778 - accuracy: 0.9368 - val_loss: 0.4762 - val_accuracy: 0.8552 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "138/138 [==============================] - 13s 94ms/step - loss: 0.1712 - accuracy: 0.9384 - val_loss: 0.4764 - val_accuracy: 0.8559 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.1707 - accuracy: 0.9361 - val_loss: 0.4761 - val_accuracy: 0.8552 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.1695 - accuracy: 0.9395 - val_loss: 0.4758 - val_accuracy: 0.8552 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.1747 - accuracy: 0.9390\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.1747 - accuracy: 0.9390 - val_loss: 0.4757 - val_accuracy: 0.8545 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "138/138 [==============================] - 13s 95ms/step - loss: 0.1686 - accuracy: 0.9411 - val_loss: 0.4757 - val_accuracy: 0.8538 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, ZeroPadding2D, BatchNormalization\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(96,(11,11),strides=4,activation='relu',input_shape=X_train.shape[1:],padding='valid'))\n",
    "model.add(MaxPool2D((3,3),strides=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(ZeroPadding2D(padding=2))\n",
    "model.add(Conv2D(256,(5,5),activation='relu',padding='same'))\n",
    "model.add(MaxPool2D((3,3), strides=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(ZeroPadding2D(padding=1))\n",
    "model.add(Conv2D(384,(3,3),activation='relu',padding='same'))\n",
    "\n",
    "model.add(ZeroPadding2D(padding=1))\n",
    "model.add(Conv2D(384,(3,3),activation='relu',padding='same'))\n",
    "\n",
    "model.add(ZeroPadding2D(padding=1))\n",
    "model.add(Conv2D(256,(3,3),activation='relu',padding='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096,activation=\"relu\"))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(4096,activation=\"relu\"))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(48,activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.optimizers.SGD(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n",
    "#callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy', factor=0.1, patience=5, verbose=1,\n",
    "    mode='max', min_delta=0.0001, cooldown=2, min_lr=0)\n",
    "epochs = 50\n",
    "history = model.fit(X_train, y_train_e, batch_size=32, epochs=epochs,\n",
    "validation_data=(X_val, y_val_e), callbacks = [callback])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "InveptionResNetv2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
