{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, MaxPool2D, UpSampling2D, AveragePooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Flatten, Dense, Add, Multiply, BatchNormalization, Dropout, concatenate\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.load(\"lib/datasets/X_train1.npy\")\n",
    "X_test = np.load(\"lib/datasets/X_test1.npy\" )\n",
    "X_val = np.load(\"lib/datasets/X_val1.npy\")\n",
    "y_train_e = np.load(\"lib/datasets/y_train_e1.npy\")\n",
    "y_test_e = np.load(\"lib/datasets/y_test_e1.npy\")\n",
    "y_val_e = np.load(\"lib/datasets/y_val_e1.npy\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node 'inception_resnet_v2/conv2d_366/Conv2D' defined at (most recent call last):\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2915, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\dokee\\AppData\\Local\\Temp/ipykernel_28132/489565320.py\", line 8, in <module>\n      history = model.fit(X_train, y_train_e, batch_size=32, epochs=epochs, validation_data=(X_val, y_val_e))\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 240, in convolution_op\n      name=self.__class__.__name__)\nNode: 'inception_resnet_v2/conv2d_366/Conv2D'\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 36987920 bytes.\n  Profiling failure on CUDNN engine 1: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16785536 bytes.\n  Profiling failure on CUDNN engine 0#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 0: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 2#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 33816576 bytes.\n  Profiling failure on CUDNN engine 2: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 33816576 bytes.\n  Profiling failure on CUDNN engine 4#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1091854336 bytes.\n  Profiling failure on CUDNN engine 4: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1091854336 bytes.\n  Profiling failure on CUDNN engine 5#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 150192128 bytes.\n  Profiling failure on CUDNN engine 5: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 150192128 bytes.\n\t [[{{node inception_resnet_v2/conv2d_366/Conv2D}}]] [Op:__inference_train_function_59202]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28132/489565320.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m      7\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_e\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val_e\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node 'inception_resnet_v2/conv2d_366/Conv2D' defined at (most recent call last):\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2915, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\dokee\\AppData\\Local\\Temp/ipykernel_28132/489565320.py\", line 8, in <module>\n      history = model.fit(X_train, y_train_e, batch_size=32, epochs=epochs, validation_data=(X_val, y_val_e))\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"C:\\Users\\dokee\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 240, in convolution_op\n      name=self.__class__.__name__)\nNode: 'inception_resnet_v2/conv2d_366/Conv2D'\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 36987920 bytes.\n  Profiling failure on CUDNN engine 1: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16785536 bytes.\n  Profiling failure on CUDNN engine 0#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 0: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 2#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 33816576 bytes.\n  Profiling failure on CUDNN engine 2: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 33816576 bytes.\n  Profiling failure on CUDNN engine 4#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1091854336 bytes.\n  Profiling failure on CUDNN engine 4: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1091854336 bytes.\n  Profiling failure on CUDNN engine 5#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 150192128 bytes.\n  Profiling failure on CUDNN engine 5: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 150192128 bytes.\n\t [[{{node inception_resnet_v2/conv2d_366/Conv2D}}]] [Op:__inference_train_function_59202]"
     ]
    }
   ],
   "source": [
    "model = InceptionResNetV2(weights = None, classes = 47)\n",
    "callback = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    .045, 2, .94, staircase=False, name=None\n",
    ")\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.optimizers.RMSprop(learning_rate=callback, epsilon = 1.0),\n",
    "              metrics=['accuracy'])\n",
    "epochs = 20\n",
    "history = model.fit(X_train, y_train_e, batch_size=32, epochs=epochs, validation_data=(X_val, y_val_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class IRV2():\n",
    "    def __init__(self, input_shape, n_classes, activation, p=1, t=2, r=1):\n",
    "        self.input_shape = input_shape\n",
    "        self.n_classes = n_classes\n",
    "        self.activation = activation\n",
    "\n",
    "    def build_model(self):\n",
    "        input_data = Input(shape=self.input_shape)\n",
    "        print(input_data.shape)\n",
    "        stem = self.stem(input_data)\n",
    "        print(stem.shape)\n",
    "        ira = Activation(\"relu\")(stem)\n",
    "        for i in range(5):\n",
    "            ira = self.IRA(ira)\n",
    "        print(ira.shape)\n",
    "        ra = self.RA(ira)\n",
    "        print(ra.shape)\n",
    "        irb = Activation(\"relu\")(ra)\n",
    "        for i in range(10):\n",
    "            irb = self.IRB(irb)\n",
    "        print(irb.shape)\n",
    "        rb = self.RB(irb)\n",
    "        print(rb.shape)\n",
    "        irc = Activation(\"relu\")(rb)\n",
    "        for i in range(5):\n",
    "            irc = self.IRC(irc)\n",
    "        print(irc.shape)\n",
    "        pool = AveragePooling2D(8)(irc)\n",
    "        print(pool.shape)\n",
    "        drop = Dropout(0.8)(pool)\n",
    "        final = Dense(self.n_classes, activation= self.activation)(drop)\n",
    "        model = Model(inputs = input_data, outputs = final)\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def stem(self, input_data):\n",
    "        conv_1 = Conv2D(32, (3,3), strides=2, padding=\"valid\")(input_data)\n",
    "        conv_1 = BatchNormalization()(conv_1)\n",
    "        conv_1 = Activation('relu')(conv_1)\n",
    "\n",
    "        conv_2 = Conv2D(32, (3, 3), padding=\"valid\")(conv_1)\n",
    "        conv_2 = BatchNormalization()(conv_2)\n",
    "        conv_2 = Activation('relu')(conv_2)\n",
    "\n",
    "        conv_3 = Conv2D(64, (3, 3), padding=\"same\")(conv_2)\n",
    "        conv_3 = BatchNormalization()(conv_3)\n",
    "        conv_3 = Activation('relu')(conv_3)\n",
    "\n",
    "        pool_1 = MaxPool2D((3,3), strides=2, padding='valid')(conv_3)\n",
    "\n",
    "        conv_4 = Conv2D(96, (3, 3), strides = 2, padding=\"valid\")(conv_3)\n",
    "        conv_4 = BatchNormalization()(conv_4)\n",
    "        conv_4 = Activation('relu')(conv_4)\n",
    "\n",
    "        conc_1 = concatenate([pool_1, conv_4])\n",
    "\n",
    "        conv_5_1 = Conv2D(64, (1, 1), padding=\"same\")(conc_1)\n",
    "        conv_5_1 = BatchNormalization()(conv_5_1)\n",
    "        conv_5_1 = Activation('relu')(conv_5_1)\n",
    "\n",
    "        conv_6_1 = Conv2D(96, (3, 3), padding=\"valid\")(conv_5_1)\n",
    "        conv_6_1 = BatchNormalization()(conv_6_1)\n",
    "        conv_6_1 = Activation('relu')(conv_6_1)\n",
    "\n",
    "        conv_5_2 = Conv2D(64, (1, 1), padding=\"same\")(conc_1)\n",
    "        conv_5_2 = BatchNormalization()(conv_5_2)\n",
    "        conv_5_2 = Activation('relu')(conv_5_2)\n",
    "\n",
    "        conv_6_2 = Conv2D(64, (7, 1), padding=\"same\")(conv_5_2)\n",
    "        conv_6_2 = BatchNormalization()(conv_6_2)\n",
    "        conv_6_2 = Activation('relu')(conv_6_2)\n",
    "\n",
    "        conv_7_2 = Conv2D(64, (1, 7), padding=\"same\")(conv_6_2)\n",
    "        conv_7_2 = BatchNormalization()(conv_7_2)\n",
    "        conv_7_2 = Activation('relu')(conv_7_2)\n",
    "\n",
    "        conv_8_2 = Conv2D(96, (3, 3), padding=\"valid\")(conv_7_2)\n",
    "        conv_8_2 = BatchNormalization()(conv_8_2)\n",
    "        conv_8_2 = Activation('relu')(conv_8_2)\n",
    "\n",
    "        conc_2 = concatenate([conv_6_1, conv_8_2])\n",
    "\n",
    "        conv_1_3 = Conv2D(192, (3,3),strides=2, padding=\"valid\")(conc_2)\n",
    "        conv_1_3 = BatchNormalization()(conv_1_3)\n",
    "        conv_1_3 = Activation(\"relu\")(conv_1_3)\n",
    "\n",
    "        pool_1_4 = MaxPool2D(strides=2, padding = \"valid\")(conc_2)\n",
    "\n",
    "        conc_3 = concatenate([conv_1_3, pool_1_4])\n",
    "\n",
    "        return conc_3\n",
    "\n",
    "    #fig 16\n",
    "    def IRA(self, input_data):\n",
    "        # relu_1 = Activation(\"relu\")(input_data)\n",
    "        relu_1 = input_data\n",
    "        b_0 = Conv2D(32, (1,1), padding=\"same\")(relu_1)\n",
    "        b_0 = BatchNormalization()(b_0)\n",
    "        b_0 = Activation(\"relu\")(b_0)\n",
    "\n",
    "        b_1 = Conv2D(32, (1, 1), padding=\"same\")(relu_1)\n",
    "        b_1 = BatchNormalization()(b_1)\n",
    "        b_1 = Activation(\"relu\")(b_1)\n",
    "        b_1 = Conv2D(32, (3, 3), padding=\"same\")(b_1)\n",
    "        b_1 = BatchNormalization()(b_1)\n",
    "        b_1 = Activation(\"relu\")(b_1)\n",
    "\n",
    "        b_2 = Conv2D(32, (1, 1), padding=\"same\")(relu_1)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(48, (3, 3), padding=\"same\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(64, (3, 3), padding=\"same\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "\n",
    "        conc_1 = concatenate([b_0, b_1, b_2])\n",
    "\n",
    "        conv = Conv2D(384, (1,1), padding=\"same\")(conc_1)\n",
    "        conv *= 0.17\n",
    "        out = Add()([conv, relu_1])\n",
    "        relu_2 = Activation(\"relu\")(out)\n",
    "\n",
    "        return relu_2\n",
    "\n",
    "    # fig 7\n",
    "    # k l m n = 256 256 384 384\n",
    "    def RA(self, input_data):\n",
    "        b_0 = MaxPool2D((3,3), strides=2, padding=\"valid\")(input_data)\n",
    "\n",
    "        b_1 = Conv2D(384, (3,3), strides=2, padding=\"valid\")(input_data)\n",
    "        b_1 = BatchNormalization()(b_1)\n",
    "        b_1 = Activation(\"relu\")(b_1)\n",
    "\n",
    "        b_2 = Conv2D(256, (1,1), padding=\"same\")(input_data)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(256, (3,3), padding=\"same\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(384, (3,3), strides=2, padding=\"valid\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "\n",
    "        conc_1 = concatenate([b_0, b_1, b_2])\n",
    "\n",
    "        return conc_1\n",
    "\n",
    "    # fig 17\n",
    "    def IRB(self, input_data):\n",
    "        b_1 = Conv2D(192, (1,1), padding=\"same\")(input_data)\n",
    "        b_1 = BatchNormalization()(b_1)\n",
    "        b_1 = Activation(\"relu\")(b_1)\n",
    "\n",
    "        b_2 = Conv2D(128, (1,1), padding=\"same\")(input_data)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(160, (1,7), padding=\"same\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(192, (7,1), padding=\"same\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "\n",
    "        conc_1 = concatenate([b_1, b_2])\n",
    "\n",
    "        conv = Conv2D(1152, (1,1), padding=\"same\")(conc_1)\n",
    "        conv *= 0.1\n",
    "        out = Add()([input_data, conv])\n",
    "        relu = Activation(\"relu\")(out)\n",
    "        return relu\n",
    "\n",
    "\n",
    "    def RB(self, input_data):\n",
    "        b_0 = MaxPool2D((3,3), strides=2, padding=\"valid\")(input_data)\n",
    "\n",
    "        b_1 = Conv2D(256, (1,1), padding=\"same\")(input_data)\n",
    "        b_1 = BatchNormalization()(b_1)\n",
    "        b_1 = Activation(\"relu\")(b_1)\n",
    "        b_1 = Conv2D(384, (3,3),strides=2, padding=\"valid\")(b_1)\n",
    "        b_1 = BatchNormalization()(b_1)\n",
    "        b_1 = Activation(\"relu\")(b_1)\n",
    "\n",
    "        b_2 = Conv2D(256, (1,1), padding=\"same\")(input_data)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(288, (3,3),strides=2, padding=\"valid\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "\n",
    "        b_3 = Conv2D(256, (1,1), padding=\"same\")(input_data)\n",
    "        b_3 = BatchNormalization()(b_3)\n",
    "        b_3 = Activation(\"relu\")(b_3)\n",
    "        b_3 = Conv2D(288, (3,3), padding=\"same\")(b_3)\n",
    "        b_3 = BatchNormalization()(b_3)\n",
    "        b_3 = Activation(\"relu\")(b_3)\n",
    "        b_3 = Conv2D(320, (3,3),strides=2, padding=\"valid\")(b_3)\n",
    "        b_3 = BatchNormalization()(b_3)\n",
    "        b_3 = Activation(\"relu\")(b_3)\n",
    "\n",
    "        conc = concatenate([b_0,b_1,b_2,b_3])\n",
    "        return conc\n",
    "\n",
    "    def IRC(self, input_data):\n",
    "        b_1 = Conv2D(192, (1,1), padding=\"same\")(input_data)\n",
    "        b_1 = BatchNormalization()(b_1)\n",
    "        b_1 = Activation(\"relu\")(b_1)\n",
    "\n",
    "        b_2 = Conv2D(192, (1,1), padding=\"same\")(input_data)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(224, (1,3), padding=\"same\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "        b_2 = Conv2D(256, (3,1), padding=\"same\")(b_2)\n",
    "        b_2 = BatchNormalization()(b_2)\n",
    "        b_2 = Activation(\"relu\")(b_2)\n",
    "\n",
    "        conc_1 = concatenate([b_1, b_2])\n",
    "\n",
    "        conv = Conv2D(2144, (1,1), padding=\"same\")(conc_1)\n",
    "        conv*= 0.2\n",
    "        out = Add()([input_data, conv])\n",
    "        relu = Activation(\"relu\")(out)\n",
    "        return relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 299, 299, 3)\n",
      "(None, 35, 35, 384)\n",
      "(None, 35, 35, 384)\n",
      "(None, 17, 17, 1152)\n",
      "(None, 17, 17, 1152)\n",
      "(None, 8, 8, 2144)\n",
      "(None, 8, 8, 2144)\n",
      "(None, 1, 1, 2144)\n"
     ]
    }
   ],
   "source": [
    "model = IRV2(X_train.shape[1:], 47, activation= 'softmax').build_model()\n",
    "# decay = .9 e = 1.0 lr = 0.045, exp rate = 0.94\n",
    "callback = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    .045, 2, .94, staircase=False, name=None\n",
    ")\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.optimizers.RMSprop(learning_rate=callback, epsilon = 1.0),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_memory_usage(batch_size, model):\n",
    "    import numpy as np\n",
    "    try:\n",
    "        from keras import backend as K\n",
    "    except:\n",
    "        from tensorflow.keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    internal_model_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        layer_type = l.__class__.__name__\n",
    "        if layer_type == 'Model':\n",
    "            internal_model_mem_count += get_model_memory_usage(batch_size, l)\n",
    "        single_layer_mem = 1\n",
    "        out_shape = l.output_shape\n",
    "        if type(out_shape) is list:\n",
    "            out_shape = out_shape[0]\n",
    "        for s in out_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in model.trainable_weights])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in model.non_trainable_weights])\n",
    "\n",
    "    number_size = 4.0\n",
    "    if K.floatx() == 'float16':\n",
    "        number_size = 2.0\n",
    "    if K.floatx() == 'float64':\n",
    "        number_size = 8.0\n",
    "\n",
    "    total_memory = number_size * (batch_size * shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3) + internal_model_mem_count\n",
    "    return gbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.809"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_memory_usage(32, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "110/110 [==============================] - ETA: 0s - loss: 3.9132 - accuracy: 0.1703"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29040/4192271079.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     mode='max', min_delta=0.0001, cooldown=2, min_lr=0)\n\u001b[0;32m      4\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_e\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val_e\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy', factor=0.01, patience=5, verbose=1,\n",
    "    mode='max', min_delta=0.0001, cooldown=2, min_lr=0)\n",
    "epochs = 20\n",
    "history = model.fit(X_train, y_train_e, batch_size=32, epochs=epochs, validation_data=(X_val, y_val_e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
